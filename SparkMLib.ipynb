{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SparkMLib.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPQzTwEE6YzDKX/OYmXobg1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahfuz978/Apache-Spark/blob/main/SparkMLib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbXsx5ZuCp7t"
      },
      "source": [
        "# Spark MLib\n",
        "\n",
        "Linear Regression model is one the oldest and widely used machine learning approach which assumes a relationship between dependent and independent variables. For example, a modeler might want to predict the forecast of the rain based on the humidity ratio. Linear Regression consists of the best fitting line through the scattered points on the graph and the best fitting line is known as the regression line.\n",
        "\n",
        "The goal of this exercise to predict the housing prices by the given features. Let's predict the prices of the Boston Housing dataset by considering MEDV as the output variable and all the other variables as input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUdEtmPnCvaG",
        "outputId": "5e7262fd-a38f-458e-f654-84e1582db3d8"
      },
      "source": [
        "!wget https://gist.githubusercontent.com/ghaiyur-musubi/eb32744bd0c24b62efe1ca84d50938fc/raw/b17119a2755876c4bdf88e10f015d5be84c5d003/BostonHousing.csv"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-24 17:13:15--  https://gist.githubusercontent.com/ghaiyur-musubi/eb32744bd0c24b62efe1ca84d50938fc/raw/b17119a2755876c4bdf88e10f015d5be84c5d003/BostonHousing.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35735 (35K) [text/plain]\n",
            "Saving to: ‘BostonHousing.csv.2’\n",
            "\n",
            "BostonHousing.csv.2 100%[===================>]  34.90K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2021-08-24 17:13:16 (12.1 MB/s) - ‘BostonHousing.csv.2’ saved [35735/35735]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1QL8vCOC6EX",
        "outputId": "a42fa454-116b-47ec-b4a2-2366cdfb9c60"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.1.2)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmWCks08DC_G"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config(\"spark.ui.port\", \"4050\")\\\n",
        "        .getOrCreate()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3vgnhSrENMz",
        "outputId": "8c96ed0f-a9a7-4862-c786-46d77836275c"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "df = spark.read.csv(\"BostonHousing.csv\", inferSchema = True, header = True)\n",
        "df.show(20)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+\n",
            "|   crim|  zn|indus|chas|  nox|   rm|  age|   dis|rad|tax|ptratio|     b|lstat|medv|\n",
            "+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+\n",
            "|0.00632|18.0| 2.31|   0|0.538|6.575| 65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|\n",
            "|0.02731| 0.0| 7.07|   0|0.469|6.421| 78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|\n",
            "|0.02729| 0.0| 7.07|   0|0.469|7.185| 61.1|4.9671|  2|242|   17.8|392.83| 4.03|34.7|\n",
            "|0.03237| 0.0| 2.18|   0|0.458|6.998| 45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|\n",
            "|0.06905| 0.0| 2.18|   0|0.458|7.147| 54.2|6.0622|  3|222|   18.7| 396.9| 5.33|36.2|\n",
            "|0.02985| 0.0| 2.18|   0|0.458| 6.43| 58.7|6.0622|  3|222|   18.7|394.12| 5.21|28.7|\n",
            "|0.08829|12.5| 7.87|   0|0.524|6.012| 66.6|5.5605|  5|311|   15.2| 395.6|12.43|22.9|\n",
            "|0.14455|12.5| 7.87|   0|0.524|6.172| 96.1|5.9505|  5|311|   15.2| 396.9|19.15|27.1|\n",
            "|0.21124|12.5| 7.87|   0|0.524|5.631|100.0|6.0821|  5|311|   15.2|386.63|29.93|16.5|\n",
            "|0.17004|12.5| 7.87|   0|0.524|6.004| 85.9|6.5921|  5|311|   15.2|386.71| 17.1|18.9|\n",
            "|0.22489|12.5| 7.87|   0|0.524|6.377| 94.3|6.3467|  5|311|   15.2|392.52|20.45|15.0|\n",
            "|0.11747|12.5| 7.87|   0|0.524|6.009| 82.9|6.2267|  5|311|   15.2| 396.9|13.27|18.9|\n",
            "|0.09378|12.5| 7.87|   0|0.524|5.889| 39.0|5.4509|  5|311|   15.2| 390.5|15.71|21.7|\n",
            "|0.62976| 0.0| 8.14|   0|0.538|5.949| 61.8|4.7075|  4|307|   21.0| 396.9| 8.26|20.4|\n",
            "|0.63796| 0.0| 8.14|   0|0.538|6.096| 84.5|4.4619|  4|307|   21.0|380.02|10.26|18.2|\n",
            "|0.62739| 0.0| 8.14|   0|0.538|5.834| 56.5|4.4986|  4|307|   21.0|395.62| 8.47|19.9|\n",
            "|1.05393| 0.0| 8.14|   0|0.538|5.935| 29.3|4.4986|  4|307|   21.0|386.85| 6.58|23.1|\n",
            "| 0.7842| 0.0| 8.14|   0|0.538| 5.99| 81.7|4.2579|  4|307|   21.0|386.75|14.67|17.5|\n",
            "|0.80271| 0.0| 8.14|   0|0.538|5.456| 36.6|3.7965|  4|307|   21.0|288.99|11.69|20.2|\n",
            "| 0.7258| 0.0| 8.14|   0|0.538|5.727| 69.5|3.7965|  4|307|   21.0|390.95|11.28|18.2|\n",
            "+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWyQZaS-FCw5",
        "outputId": "a68e9afd-f469-4758-e6d7-f43d12f26056"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- crim: double (nullable = true)\n",
            " |-- zn: double (nullable = true)\n",
            " |-- indus: double (nullable = true)\n",
            " |-- chas: integer (nullable = true)\n",
            " |-- nox: double (nullable = true)\n",
            " |-- rm: double (nullable = true)\n",
            " |-- age: double (nullable = true)\n",
            " |-- dis: double (nullable = true)\n",
            " |-- rad: integer (nullable = true)\n",
            " |-- tax: integer (nullable = true)\n",
            " |-- ptratio: double (nullable = true)\n",
            " |-- b: double (nullable = true)\n",
            " |-- lstat: double (nullable = true)\n",
            " |-- medv: double (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG7YHBIUFXRW",
        "outputId": "2c1823ed-b135-4c2d-8437-ac88f8e940c6"
      },
      "source": [
        "df.describe().show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+------------------+------------------+------------------+\n",
            "|summary|              crim|                zn|             indus|              chas|                nox|                rm|               age|              dis|              rad|               tax|           ptratio|                 b|             lstat|              medv|\n",
            "+-------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+------------------+------------------+------------------+\n",
            "|  count|               506|               506|               506|               506|                506|               506|               506|              506|              506|               506|               506|               506|               506|               506|\n",
            "|   mean|3.6135235573122535|11.363636363636363|11.136778656126504|0.0691699604743083| 0.5546950592885372| 6.284634387351787| 68.57490118577078|3.795042687747034|9.549407114624506| 408.2371541501976|18.455533596837967|356.67403162055257|12.653063241106723|22.532806324110698|\n",
            "| stddev| 8.601545105332491| 23.32245299451514| 6.860352940897589|0.2539940413404101|0.11587767566755584|0.7026171434153232|28.148861406903595| 2.10571012662761|8.707259384239366|168.53711605495903|2.1649455237144455| 91.29486438415782| 7.141061511348571| 9.197104087379815|\n",
            "|    min|           0.00632|               0.0|              0.46|                 0|              0.385|             3.561|               2.9|           1.1296|                1|               187|              12.6|              0.32|              1.73|               5.0|\n",
            "|    max|           88.9762|             100.0|             27.74|                 1|              0.871|              8.78|             100.0|          12.1265|               24|               711|              22.0|             396.9|             37.97|              50.0|\n",
            "+-------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+------------------+------------------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jl5_jTlvFokk"
      },
      "source": [
        "## Analyzing the data\n",
        "Now that we have uploaded the dataset, we can start analyzing. For our linear regression model we need to import two modules from Pyspark i.e. Vector Assembler and Linear Regression. Vector Assembler is a transformer that assembles all the features into one vector from multiple columns that contain type double. We could have used StringIndexer if any of our columns contains string values to convert it into numeric values. Luckily, the BostonHousing dataset only contains double values, so we don't need to worry about StringIndexer for now.\n",
        "\n",
        "\n",
        "\n",
        "Next step is to convert all the features from different columns into a single column and let's call this new vector column as 'Attributes' in the outputCol.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynbFwfzdFbgW",
        "outputId": "eab0b92a-a44d-4e12-8bc6-b91cfc3836d8"
      },
      "source": [
        "# input all the features into one vector column\n",
        "assembler = VectorAssembler(inputCols = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat'], outputCol = \"Attributes\")\n",
        "\n",
        "output = assembler.transform(df)\n",
        "\n",
        "#Input vs. Output\n",
        "finalized_data = output.select(\"Attributes\", \"medv\")\n",
        "\n",
        "finalized_data.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----+\n",
            "|          Attributes|medv|\n",
            "+--------------------+----+\n",
            "|[0.00632,18.0,2.3...|24.0|\n",
            "|[0.02731,0.0,7.07...|21.6|\n",
            "|[0.02729,0.0,7.07...|34.7|\n",
            "|[0.03237,0.0,2.18...|33.4|\n",
            "|[0.06905,0.0,2.18...|36.2|\n",
            "|[0.02985,0.0,2.18...|28.7|\n",
            "|[0.08829,12.5,7.8...|22.9|\n",
            "|[0.14455,12.5,7.8...|27.1|\n",
            "|[0.21124,12.5,7.8...|16.5|\n",
            "|[0.17004,12.5,7.8...|18.9|\n",
            "|[0.22489,12.5,7.8...|15.0|\n",
            "|[0.11747,12.5,7.8...|18.9|\n",
            "|[0.09378,12.5,7.8...|21.7|\n",
            "|[0.62976,0.0,8.14...|20.4|\n",
            "|[0.63796,0.0,8.14...|18.2|\n",
            "|[0.62739,0.0,8.14...|19.9|\n",
            "|[1.05393,0.0,8.14...|23.1|\n",
            "|[0.7842,0.0,8.14,...|17.5|\n",
            "|[0.80271,0.0,8.14...|20.2|\n",
            "|[0.7258,0.0,8.14,...|18.2|\n",
            "+--------------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP-catWCHUWe"
      },
      "source": [
        "Here, 'Attributes' are in the input features from all the columns and 'medv' is the target column. Next, we should split the training and testing data according to our dataset (0.8 and 0.2 in this case)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KDQK2n_HK5K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b66997f7-888c-4b65-d5cd-8b35f85f5c20"
      },
      "source": [
        "# split training and testing data\n",
        "train_data, test_data = finalized_data.randomSplit([.8,.2])\n",
        "\n",
        "regressor = LinearRegression(featuresCol = 'Attributes', labelCol = 'medv')\n",
        "\n",
        "# learn to fit the model in the training set\n",
        "regressor = regressor.fit(train_data)\n",
        "\n",
        "# to predict the prices on the training set\n",
        "pred = regressor.evaluate(test_data)\n",
        "\n",
        "#predict the model\n",
        "pred.predictions.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----+------------------+\n",
            "|          Attributes|medv|        prediction|\n",
            "+--------------------+----+------------------+\n",
            "|[0.01096,55.0,2.2...|22.0| 27.48688139596633|\n",
            "|[0.01439,60.0,2.9...|29.1|31.628212136761007|\n",
            "|[0.01501,90.0,1.2...|50.0| 45.93363674116101|\n",
            "|[0.01538,90.0,3.7...|44.0|37.398435622287224|\n",
            "|[0.02055,85.0,0.7...|24.7| 25.44992282340779|\n",
            "|[0.0315,95.0,1.47...|34.9|30.367294499312635|\n",
            "|[0.03427,0.0,5.19...|19.5|20.268570052446712|\n",
            "|[0.03445,82.5,2.0...|24.1|29.459723839483704|\n",
            "|[0.03466,35.0,6.0...|19.4|23.637147193230806|\n",
            "|[0.03871,52.5,5.3...|23.2| 27.13580957592068|\n",
            "|[0.03961,0.0,5.19...|21.1|20.849268799603927|\n",
            "|[0.04203,28.0,15....|22.9|28.641847217669763|\n",
            "|[0.04666,80.0,1.5...|30.3| 32.74254163744575|\n",
            "|[0.05023,35.0,6.0...|17.1|20.248219345526834|\n",
            "|[0.05302,0.0,3.41...|28.7|30.478950989955578|\n",
            "|[0.05644,40.0,6.4...|32.4|37.324427626521796|\n",
            "|[0.05735,0.0,4.49...|26.6| 27.49772395467309|\n",
            "|[0.06129,20.0,3.3...|46.0|  41.4241344312391|\n",
            "|[0.06211,40.0,1.2...|22.9|20.991052856273896|\n",
            "|[0.06263,0.0,11.9...|22.4| 23.43986429842779|\n",
            "+--------------------+----+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+--------------------+----+------------------+\n",
            "|          Attributes|medv|        prediction|\n",
            "+--------------------+----+------------------+\n",
            "|[0.01439,60.0,2.9...|29.1| 32.15047042677705|\n",
            "|[0.0187,85.0,4.15...|23.1|25.952048026105636|\n",
            "|[0.02187,60.0,2.9...|31.1| 32.60672368007344|\n",
            "|[0.02729,0.0,7.07...|34.7| 30.23725482092142|\n",
            "|[0.02985,0.0,2.18...|28.7| 25.04078196813899|\n",
            "|[0.03551,25.0,4.8...|22.9|25.508168118960985|\n",
            "|[0.03578,20.0,3.3...|45.4|38.567155259468265|\n",
            "|[0.03584,80.0,3.3...|23.5|31.277350662262098|\n",
            "|[0.03615,80.0,4.9...|27.9|32.754674304435476|\n",
            "|[0.03705,20.0,3.3...|35.4| 34.32847930048007|\n",
            "|[0.03738,0.0,5.19...|20.7|21.229749218983088|\n",
            "|[0.03871,52.5,5.3...|23.2|27.757418171178085|\n",
            "|[0.04294,28.0,15....|20.6|27.829780009610136|\n",
            "|[0.04337,21.0,5.6...|20.5| 24.31488978145404|\n",
            "|[0.0459,52.5,5.32...|22.3|27.914102471286565|\n",
            "|[0.05023,35.0,6.0...|17.1| 20.58820262238895|\n",
            "|[0.05083,0.0,5.19...|22.2|21.796784457933583|\n",
            "|[0.0536,21.0,5.64...|25.0| 27.75440294262163|\n",
            "|[0.05372,0.0,13.9...|27.1| 27.59661597504524|\n",
            "|[0.05561,70.0,2.2...|29.0| 32.38284637766918|\n",
            "+--------------------+----+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH9-hEpOJJLd",
        "outputId": "5701ea69-4412-497c-fef0-a97ebcca508b"
      },
      "source": [
        "# we can alo print the coefficient and intercept of the regressiong model\n",
        "\n",
        "coeff = regressor.coefficients\n",
        "\n",
        "#X and Y intercepts\n",
        "\n",
        "intr = regressor.intercept\n",
        "\n",
        "\n",
        "print(\"the coefficient of the model is %a\" %coeff)\n",
        "print(\"the intercept of the model is %f\" %intr )"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the coefficient of the model is DenseVector([-0.1159, 0.0574, 0.0512, 1.6454, -22.2679, 3.4674, 0.0017, -1.5458, 0.3235, -0.0126, -0.9546, 0.0075, -0.5104])\n",
            "the intercept of the model is 41.499323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqIjxlIpLtIC"
      },
      "source": [
        "## Basic statistical analysis\n",
        "\n",
        "Once we are done with the basic linear regression operation, we can go a bit further and analyze our model statistically by importing RegressionEvaluator module from Pyspark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx1kp4z-LfE3",
        "outputId": "1d789fcf-2d64-4efa-8d78-150f56fd5f45"
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "eval = RegressionEvaluator(labelCol = \"medv\", predictionCol = \"prediction\", metricName = \"rmse\")\n",
        "\n",
        "# Root mean square error\n",
        "rmse = eval.evaluate(pred.predictions)\n",
        "print(\"RMSE: %.3f\" %rmse)\n",
        "\n",
        "\n",
        "# mean square error\n",
        "mse = eval.evaluate(pred.predictions, {eval.metricName: 'mse'})\n",
        "print(\"MSE: %.3f\" %mse)\n",
        "\n",
        "#mean absolute error\n",
        "mae = eval.evaluate(pred.predictions, {eval.metricName: 'mae'})\n",
        "print(\"MAE: %.3f\" %mae)\n",
        "\n",
        "\n",
        "# r2 - coefficient of determination\n",
        "r2 = eval.evaluate(pred.predictions, {eval.metricName: \"r2\"})\n",
        "print(\"R2: %.3f\" %r2)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 4.684\n",
            "MSE: 21.942\n",
            "MAE: 3.556\n",
            "R2: 0.757\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwLL8BxgOsAB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}